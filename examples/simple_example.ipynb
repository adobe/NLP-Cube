{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP-Cube Quick Tutorial\n",
    "\n",
    "Install NLP-Cube with ``pip3 install -U nlpcube``. Use the -U flag to ensure the installation of the latest version even if you already have installed NLP-Cube.\n",
    "\n",
    "To use NLP-Cube simply import and initialize the Cube object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-AgZEVNW9Sv"
   },
   "outputs": [],
   "source": [
    "from cube.api import Cube\n",
    "\n",
    "cube=Cube(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, load a model. We'll request English model. Because this is a new install, we don't have any model locally. The ``.load(\"en\")`` will automatically download the model for us.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "M99mLVvAXUlb",
    "outputId": "4d8ff4e1-989f-4904-f813-dc38eed46ca3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest version found online: en-1.1\n",
      "Download complete, decompressing files ...                                         \n",
      "Model downloaded successfully.\n",
      "Checking for associated vector embeddings file [wiki.dummy.vec] ...\n",
      "\n",
      "\tLoading embeddings... \n",
      "\tLoading tokenization model ...\n",
      "\tLoading lemmatization model ...\n",
      "\tLoading tagger model ...\n",
      "\tLoading parser model ...\n",
      "Model loading complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cube.load(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, simply call ``cube(\"your-text-as-a-string-here\")``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "a1gsnXZbdj_G",
    "outputId": "338d4315-fec5-4df5-e421-1e4a9cb60184"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tAll\tall\tDET\tPDT\t_\t3\tdet:predet\t_\n",
      "2\tthe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t3\tdet\t_\n",
      "3\tfaith\tfaith\tNOUN\tNN\tNumber=Sing\t9\tnsubj\t_\n",
      "4\the\the\tPRON\tPRP\tCase=Nom|Gender=Masc|Number=Sing|Person=3|PronType=Prs\t6\tnsubj\t_\n",
      "5\thad\thave\tAUX\tVBD\tMood=Ind|Tense=Past|VerbForm=Fin\t6\taux\t_\n",
      "6\thad\thave\tVERB\tVBN\tTense=Past|VerbForm=Part\t3\tacl:relcl\tSpaceAfter=No\n",
      "7\t,\t,\tPUNCT\t,\t_\t9\tpunct\t_\n",
      "8\thad\thave\tAUX\tVBD\tMood=Ind|Tense=Past|VerbForm=Fin\t9\taux\t_\n",
      "9\thad\thave\tVERB\tVBN\tTense=Past|VerbForm=Part\t0\troot\t_\n",
      "10\tno\tno\tDET\tDT\t_\t11\tdet\t_\n",
      "11\teffect\teffect\tNOUN\tNN\tNumber=Sing\t9\tobj\t_\n",
      "12\ton\ton\tADP\tIN\t_\t14\tcase\t_\n",
      "13\tthe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t14\tdet\t_\n",
      "14\toutcome\toutcome\tNOUN\tNN\tNumber=Sing\t11\tnmod\t_\n",
      "15\tof\tof\tADP\tIN\t_\t17\tcase\t_\n",
      "16\this\the\tPRON\tPRP$\tGender=Masc|Number=Sing|Person=3|Poss=Yes|PronType=Prs\t17\tnmod:poss\t_\n",
      "17\tlife\tlife\tNOUN\tNN\tNumber=Sing\t14\tnmod\tSpaceAfter=No\n",
      "18\t.\t.\tPUNCT\t.\t_\t9\tpunct\tSpaceAfter=No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text=\"All the faith he had had, had had no effect on the outcome of his life.\"\n",
    "\n",
    "sentences=cube(text)\n",
    "\n",
    "for sentence in sentences:\n",
    "  for entry in sentence:\n",
    "    print(str(entry.index)+\"\\t\"+entry.word+\"\\t\"+entry.lemma+\"\\t\"+entry.upos+\"\\t\"+entry.xpos+\"\\t\"+entry.attrs+\"\\t\"+str(entry.head)+\"\\t\"+str(entry.label)+\"\\t\"+entry.space_after)\n",
    "  print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OopcPVWatXeh"
   },
   "source": [
    "The text is first segmented at the sentence level, then tokenized, and then POS tagged, lemmtized and parsed. \n",
    "\n",
    "The returned ``sentences`` object is simply an array of sentences, where each sentence is a list of objects with all the above properties. \n",
    "\n",
    "For example, if we want to collect all lemmas from the first sentence and print them out as a single string while minding the space after each token (entry), we'll do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all the faith he have have, have have no effect on the outcome of he life.\n"
     ]
    }
   ],
   "source": [
    "lemmas = \"\"\n",
    "for entry in sentences[0]: # note we selected the first sentence (sentence[0])\n",
    "    lemmas += entry.lemma\n",
    "    # now, we look for a space after the lemma to add it as well\n",
    "    if not \"SpaceAfter=No\" in entry.space_after:\n",
    "        lemmas += \" \"\n",
    "\n",
    "print(lemmas)  \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cube-simple-example.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
