[TieredTokenizerConfig]
base = corpus/trained_models/ro/tokenizer/v3
patience = 20
raw_test_file = corpus/ud-test-v2.0-conll2017/input/conll17-ud-test-2017-05-09/ro.txt
ss_char_embeddings_size = 100
ss_char_peek_count = 5
ss_lstm_dropout = 0.33
ss_lstm_layers = 1
ss_lstm_size = 64
ss_mlp_dropouts = [0.33]
ss_mlp_layers = [100]
ss_peek_lstm_dropout = 0.33
ss_peek_lstm_layers = 1
ss_peek_lstm_size = 64
tok_char_embeddings_size = 100
tok_char_lstm_dropout = 0.33
tok_char_lstm_layers = 1
tok_char_lstm_size = 100
tok_char_peek_lstm_dropout = 0.33
tok_char_peek_lstm_layers = 1
tok_char_peek_lstm_size = 50
tok_mlp_dropouts = [0.33]
tok_mlp_layers = [100]
tok_word_embeddings_size = 100
tok_word_lstm_dropout = 0.33
tok_word_lstm_layers = 1
tok_word_lstm_size = 50

