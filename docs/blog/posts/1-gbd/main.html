<!DOCTYPE html>
<html lang="en">

    <head>

        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <meta name="description" content="">
        <meta name="author" content="">

        <title>NLP Cube</title>

        <!-- Bootstrap core CSS -->

        <!-- Custom styles for this template -->
        <style>
            body {
                padding-top: 54px;
            }
            @media (min-width: 992px) {
                body {
                    font-family: source-sans-pro, sans-serif ;
                    padding-top: 56px;
                }
            }

        </style>
        <link href="../../../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet" media='screen'>
        <link href="../../../css/style.css" rel="stylesheet">
        <link rel="stylesheet" href="../../../vendor/font-awesome/css/font-awesome.min.css">
        <script src="../../../vendor/jquery/jquery.min.js"></script>
        <script src="../../../vendor/bootstrap/js/bootstrap.min.js"></script>
        <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML"></script>

    </head>

    <body>

        <!-- Navigation -->
        <nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top">
            <div class="container">
                <a class="navbar-brand" href="#">NLP Cube</a>
                <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav ml-auto">
                        <li class="nav-item">
                            <a class="nav-link" href="../../../index.html">Home</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="../../../start.html">Getting started</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="../../../examples.html">Examples</a>
                        </li>
                        <li class="nav-item active">
                            <a class="nav-link" href="../../../blog/list.html">Blog</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="../../../contact.html">Contact</a>
                        </li>
                    </ul>
                </div>
            </div>
        </nav>

        <!-- Page Content -->

        <div id='hero-wrapper'>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 text-center">
                        <h1 class="mt-5">NLP - Cube</h1>
                        <p class="lead">Sentence Splitting, Tokenization, Lemmatization, Part-of-speech Tagging, Dependency Parsing and Named Entity Recognition for more than 50 languages</p>
                        <ul class="list-unstyled">
                            <li><a href='https://github.com/adobe/NLP-Cube' class="btn btn-primary">Browse the code</a></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div id='sub-hero-wrapper'>
            <div class="col-lg-8 col-md-10 mx-auto">
                <h1>Graph-based decoding combined with deeplearning for named entity recognition</h1>
                <p>
                    Multi-word expression (MWE) detection is a challenging Natural Language Processing (NLP) task that consists in finding isolated tokens or sequences of tokens that form high-level structures (i.e. multi-word expressions). Naively, this can be regarded as a sequence labeling task, which in fact influenced legacy MWE methods to use this strategy. In fact, this is not far fetched, since this approach has yielded highly accurate results so far. However, we have to point a couple of task-specific details:
                </p>

                <ul>
                    <li> <strong>Sparsity:</strong> Inside an utterance there are only a couple of tokens that must be labeled as named entities or multi-word expressions. This actually yields data sparsity and could bias the model towards not identifying any of the tokens as part of a multi-word expression;</li>
                    <li> <strong>Overlapping:</strong> MWE corpora contains many examples where high-level entities share tokens among each other. There are several ways in which this issue can be mitigated, for instance training several different classifiers for each type of label;</li>
                    <li><strong>Long spans:</strong> It is often the case that MWE tokens are distantly distributed across a single utterance. Classical classifiers and even modern LSTM-based approaches are unable to detect such long range dependencies (though the later mentioned approach should), mainly because these cases are rare inside the training data and there is insufficient statistical evidence to support them.</li>

                </ul>

                <p>Our Named Entity Recognition (NER) system employs Graph-Based-Decoding (GBD) over a hybrid network architecture composed of bidirectional LSTMs for word-level encoding, with a MultiLayerPerceptron for detecting links inside entities and a unidirectional LSTM for label estimation:</p>
                <div class="text-center">
                    <form class="form-horizontal" role="form">
                        <img src="gdb-ner.png" style='width:40%; cursor:pointer'>
                        <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
                            <div class="modal-dialog  modal-lg">
                                <div class="modal-content">
                                    <div class="modal-header">
                                        <button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>

                                    </div>
                                    <div class="modal-body">
                                        <img id="mimg" src="" width="100%">
                                    </div>
                                </div><!-- /.modal-content -->
                            </div><!-- /.modal-dialog -->
                        </div><!-- /.modal -->
                    </form>
                </div>


                <p>We are currently working on integrating the NER branch into master. Until then, you can check out the source for the GDB-NER system at <a href='https://github.com/adobe/NLP-Cube/tree/dev.gbd-ner/ner'>this repository</a>, see the results obtained on the <a href="results.html">PARSEME corpus here</a>. If interested, we also encourage you to read our <a href="paper.pdf">paper draft</a></p>
                
                <p>Our graph-based encoding/decoding strategy is able to cope with overlapping high-level entities and large spans between tokens, by <strong>forcing the model to focus</strong> on the dependencies between tokens that belong to the same expression. We start off with a sequence of words as input, and convert it into a sequence of fixed-sized vectors (by combining lexical and morphological attributes for every word). After this, we use two stacked Bidirectional LSTM (BDLSTM) layers, obtaining a list of vector embeddings for each word inside the original sequence. Next, we take each vector from the internal representation and we split it using three parallel $tanh$ layers into 3 separate "projections". </p>

                <p>As such, for each word \(w_i\), we obtain three vectors which we will refer to as \(v_i^0\), \(v_i^1\) and \(v_i^2\). Finally, for every pair of words \(w_i\) and \(w_j\) with \(i\neq j\) we use single unit sigmoid activation, outputting the probability of the two words being part of the same high-level expression or not. The input for the sigmoid unit is obtained by concatenating the first vector from the split operation for word \(w_i\) (i.e. \(v_i^0\)) with the second vector of the split operation for word \(w_j\) (i.e. \(v_j^1\)). We store the resulting values in an adjacency matrix \(a\).</p>
                
                <p>Finally, we use a graph-based algorithm to decode NERs and assign the label using an unidirectional LSTM over the third projection (\(v_i^2\)) of the words contained in each expression (in natural order). Here we have to handle three cases:</p>
                <div class="text-center">
                    <form class="form-horizontal" role="form">
                        <img src="cases.png" style='width:40%; cursor:pointer'>
                        <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
                            <div class="modal-dialog  modal-lg">
                                <div class="modal-content">
                                    <div class="modal-header">
                                        <button type="button" class="close" data-dismiss="modal" aria-hidden="true">&times;</button>

                                    </div>
                                    <div class="modal-body">
                                        <img id="mimg" src="" width="100%">
                                    </div>
                                </div><!-- /.modal-content -->
                            </div><!-- /.modal-dialog -->
                        </div><!-- /.modal -->
                    </form>
                </div>
                
                <ul>
                    <li>The simplest <strong>Case (A)</strong> shows 5 interconnected graph nodes, which form a single high-level entity. Most of training data contains only this type of example, where we have to mark all the discovered tokens with the same label.</li>

                    <li><strong>Case (B)</strong> is more complex, as we have two overlapping high-level entities which share nodes 2 and 3. As such, the decoding algorithm can still easily spot the two distinct complete subgraphs, [1, 2, 3, 4] and [2, 3, 5] and mark them as two distinct entities (even if they are, or not, of the same type). </li>

                    <li><strong>Case (C)</strong> is by far the hardest. Here we have two distinct entities, with one entity [1, 2, 3, 4, 5] completely including the second entity [2, 3, 5]. We have not encountered this case in any of the training data but we feel obliged to discuss it as well. Obviously, given that the input data is correct, the decoding algorithm will always find a single entity, because all the nodes are adjacent and there is no reason to perform a split into two subgraphs. One solution to this issue is to check if any partial subgraph yields a different label then the full subgraph. This solution is only valid for entities which belong to different classes, but we feel that the two expressions sharing the same label would be highly unlikely to overlap. However, this solution may not always hold, and in the absence of real data to support Case (C).</li>
                </ul>
            </div>
        </div>


        <!-- Bootstrap core JavaScript -->
        <script src="../../../vendor/jquery/jquery.min.js"></script>
        <script src="../../../vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
        
        <script>
            $('img').on('click',function()
                        {
                var sr=$(this).attr('src'); 
                $('#mimg').attr('src',sr);
                $('#myModal').modal('show');
            });
        </script>
    </body>

</html>
